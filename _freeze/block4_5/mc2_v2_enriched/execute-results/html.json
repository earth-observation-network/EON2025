{
  "hash": "fb2f2800f8b09f367aef58063b61be0d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Räumliche Interpolation im Kontext\"\nsubtitle: \"Von Prozessen zu Modellen – mit Ecowitt-Temperaturdaten\"\nauthor: \"Chris Reudenbach, Philipps-Universität Marburg\"\nformat:\n  html:\n    toc: true\n    number-sections: true\n    code-fold: true\n    df-print: paged\nexecute:\n  echo: true\n  warning: false\n  message: false\n  cache: false\n---\n\n\n# Leitidee: Skala → Modell → Aussagekraft\n\nDie Qualität einer räumlichen Interpolation hängt zentral davon ab, **ob die Modell‑Skala zur Prozess‑Skala und zur Beobachtungs‑Skala passt**. \nUnsere Pipeline erzwingt diese Passung explizit: \n1) Wir **schätzen Prozessskalen** aus dem Variogramm (praktische Korrelationlängen **L50/L95**), \n2) **wählen/konstruieren Prädiktoren** auf passenden Glättungs‑ bzw. Gitter‑Skalen (**R_micro ≈ L50**, **R_local ≈ L95**), \n3) **tunen den Drift‑Radius \\(R^\\*\\)** via Block‑CV („U‑Kurve“) und \n4) **bewerten Methoden** (OK, KED, GAM, RF, Trend, IDW, Voronoi) bei der abgestimmten Skala.\nSo werden „Über‑“ oder „Unter‑“glättungen (Skalen‑Mismatch) sichtbar und quantifizierbar.\n\n---\n\n## Zentrale Begriffe & Formeln\n\n### Semivariogramm & Prozessvarianz\n\nDie Semivarianz für Abstand \\(h\\) ist\n\\[\n\\gamma(h) \\;=\\; \\tfrac{1}{2}\\,\\mathrm{Var}\\!\\big(Z(s)-Z(s+h)\\big).\n\\]\nDie **strukturelle Sill** \\(\\sigma_{\\text{proc}}^2\\) (ohne Nugget) beschreibt die Prozess‑Varianz (räumlich strukturierter Anteil), der **Nugget** \\(\\sigma_{\\text{inst}}^2\\) erfasst Mess‑/Mikroskalenrauschen.\nWir verwenden \\(\\sigma_{\\text{proc}} = \\sqrt{\\text{Sill}_{\\text{strukt}}}\\) im Fehlerbudget (s. u.).\n\n### Praktische Längen L50 / L95\n\nDie **praktischen Korrelationlängen** sind als Abstände definiert, bei denen die Semivarianz einen festen Anteil der strukturellen Sill erreicht:\n\\[\nL_p \\;=\\; \\inf\\!\\left\\{h \\;:\\; \\gamma(h)\\ \\ge\\ (1-p)\\,\\sigma_{\\text{proc}}^2 \\right\\},\\quad p\\in\\{0.50, 0.95\\}.\n\\]\nIntuition: Bei \\(L_{50}\\) ist die Hälfte der prozessualen Varianz „aufgebraucht“, bei \\(L_{95}\\) fast die gesamte Struktur.\n\n### Arbeits‑Radii \\(R\\): micro & local\n\nWir koppeln die Modell‑Skala an die Prozessskala:\n\\[\nR_{\\text{micro}} \\approx L_{50},\\qquad R_{\\text{local}} \\approx L_{95}.\n\\]\nDamit werden Drifts/Glättungen und Block‑Größen prozessgerecht gewählt.\n\n### Tuned Radius \\(R^\\*\\) (U‑Kurve, Block‑CV)\n\nFür Kandidaten \\(R\\) führen wir **blockierte Cross‑Validation** durch (Blockkante \\(\\approx L_{95}\\) oder \\(R\\)), um räumliche Autokorrelation nicht zu „leaken“. \nWir wählen\n\\[\nR^\\* \\;=\\; \\arg\\min_R \\ \\mathrm{RMSE}_{\\text{CV}}(R),\n\\]\nund nutzen \\(R^\\*\\) als **Drift‑Radius** für Benchmarking und finale Produkte.\n\n### Skalen‑Mismatch‑Penalty \\(g(R/L)\\)\n\nSkalenfehler entstehen, wenn die Modell‑Rohre \\(R\\) nicht zur Prozesslänge \\(L\\) passen. \nEin symmetrisches, dimensionsloses Maß ist\n\\[\ng\\!\\left(\\frac{R}{L}\\right) \\;=\\; \\tfrac{1}{2}\\!\\left(\\frac{R}{L} + \\frac{L}{R}\\right) - 1 \\;\\;\\ge 0,\n\\]\nmit Minimum \\(0\\) bei \\(R/L=1\\). Je größer die Abweichung von 1, desto höher der Mismatch‑Beitrag.\n\n### Fehlerbudget (Interpretation der RMSE)\n\nDie CV‑Fehler lassen sich heuristisch zerlegen in\n\\[\n\\mathrm{RMSE}^2 \\;\\approx\\; \\underbrace{\\sigma_{\\text{inst}}^2}_{\\text{Messrauschen}}\n\\;+\\; \\underbrace{\\sigma_{\\text{proc}}^2\\, g(R/L)}_{\\text{Skalen‑Mismatch}}\n\\;+\\; \\underbrace{\\varepsilon_{\\text{model}}^2}_{\\text{Modellrest}},\n\\]\nwobei \\(\\sigma_{\\text{inst}}\\) (angenommen/geschätzt) und \\(\\sigma_{\\text{proc}}\\) (aus dem Variogramm) stammen. \nDies macht sichtbar, **ob Fehler primär aus Messrauschen, Skalenwahl oder Modellwahl** kommen.\n\n---\n\n## Vom Konzept zur Praxis (Pipeline‑Mapping)\n\n1. **Skalen schätzen:** Variogramm \\(\\rightarrow\\) \\(\\sigma_{\\text{proc}}^2\\), \\(L_{50}\\), \\(L_{95}\\).\n2. **Skalen koppeln:** Prädiktoren glätten / Gitter wählen nach \\(R_{\\text{micro}}\\), \\(R_{\\text{local}}\\).\n3. **\\(R^\\*\\) tunen:** Block‑CV, U‑Kurve \\(\\rightarrow\\) stabiler Drift‑Radius.\n4. **Methoden benchmarken:** OK/KED/GAM/RF/Trend/IDW/Voronoi bei \\(R^\\*\\) vergleichen (RMSE/MAE/Bias, Blockgröße dokumentieren).\n5. **Produkte:** Karten/Gitter auf \\(R^\\*\\) (und ggf. \\(L_{95}\\)) schreiben; Fehlerbudget berichten.\n\n> **Merksatz:** *Nicht der „schlauste“ Algorithmus gewinnt, sondern der, dessen Skala zum Prozess passt.*\n\n\n\n\n\n# A. Raumkonzepte & Nähe\n\n> **Denkbox**  \n> *Welche „Nachbarschaft“ hat bodennahe Lufttemperatur an einem heterogenen Hang?  \n> Wie ändert sich diese Nachbarschaft von Nacht- zu Tagstunden?*\n\n*Räumliche Interpolation* ist ein Modell der **räumlich-zeitlichen Wirkungsräume** von Prozessen. Beispiele:\n\n- **Kaltluftabfluss**: gesteuert durch Relief, Fließrichtung, Mulden – mikroskalig bis mesoskalig  \n- **Tageserwärmung Südhänge**: Exposition, Einstrahlung – mikroskalig (Hang), mesoskalig (Relief)  \n- **Höhenlage**: großskaliger Trend, kann zeitabhängig dominieren oder vernachlässigbar sein  \n\n> **Exkurs: Skala & Auflösung**  \n> - Ein **20 m DEM** bildet grobe Reliefmuster ab; **1 m** bzw. **20 cm LiDAR-DGM** zeigen *Mikrorelief* (Mulden/Schwellen, Böschungen, Wege).  \n> - *Mehr Auflösung ≠ automatisch besser*: Nur sinnvoll, wenn die relevanten Prozesse *auf dieser Skala* wirken (**Skalenkongruenz**).  \n> - Hohe Auflösung kann Rauschen/Artefakte (Laserschatten, Vegetationsreste) verstärken → *ableiten, glätten, validieren*.\n\n> **Topografische Ableitungen**  \n> Slope, Aspect, TPI/TRI, Kurvaturen sind nützliche Kovariaten:  \n> - **Regression Kriging (KED/RK)**: linearer/niedriggradiger Trend + räumliche Residuen  \n> - **GAM**: flexible, nichtlineare Glätter (z. B. `s(slope, aspect)`)  \n> - **RF**: nichtparametrisch, Interaktionen “implizit”  \n> Prüft immer, ob die Kovariate auf *dieser Maßstabsebene* wirkt.\n\n> **GAM-Formelideen**  \n> - `value ~ s(x, y) + s(altitude)` – klassisch mit (Höhen-)Trend  \n> - `value ~ s(x, y) + s(slope)` – Hangneigung nichtlinear  \n> - `value ~ s(x, y) + s(slope, aspect)` – Interaktion Hang × Exposition  \n> - `value ~ s(x, y) + te(slope, aspect, altitude)` – Tensor für komplexe Reliefmuster  \n> *Hinweis:* `aspect` sinnvoll als **Eastness/Northness** (sin/cos) codieren (Zirkularität!).\n\n---\n\n# B. Daten & Vorbereitung\n\nWir nutzen zwei Ecowitt-Logger, eine Stations-GPKG, *Plot-Grenze* und ein DEM.  \nDaten werden auf **3-Stunden** aggregiert und mit topografischen Kovariaten verknüpft.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# -- Pakete laden --------------------------------------------------------------\npkgs <- c(\n  \"sf\",\"terra\",\"raster\",\"dplyr\",\"automap\",\"gstat\",\"mapview\",\"stars\",\n  \"readxl\",\"stringr\",\"tidyr\",\"purrr\",\"lubridate\",\"rprojroot\",\n  \"exactextractr\",\"zoo\",\"ggplot2\",\"viridis\",\"mgcv\",\"randomForest\",\n  \"deldir\",\"fields\",\"sp\"\n)\nto_install <- setdiff(pkgs, rownames(installed.packages()))\nif (length(to_install)) install.packages(to_install, dependencies = TRUE)\ninvisible(lapply(pkgs, function(p) suppressPackageStartupMessages(library(p, character.only = TRUE))))\n\n# -- Projektwurzel & Hilfsfunktionen (Quelle aus Repo) ------------------------\n#wd <- here::here()\n\n# -- Dateipfade ----------------------------------------------------------------\nfn_DTM        <- file.path(here::here(), \"data_2024/DEM.tif\") #\"data_2024/copernicus_DEM.tif\")\n#fn_DTM        <- file.path(here::here(), \"data_2024/copernicus_DEM.tif\")\n\nfn_stations   <- file.path(here::here(), \"data_2024/stations_prelim_modifiziert.gpkg\")\nfn_area       <- file.path(here::here(), \"data_2024/plot.shp\")\nfn_temp_FC29  <- file.path(here::here(), \"data_2024/all_GW1000A-WIFIFC29.xlsx\")\nfn_temp_DB2F  <- file.path(here::here(), \"data_2024/all_GW1000A-WIFIDB2F.xlsx\")\ncleandata_rds <- file.path(here::here(), \"data_2024/climdata.RDS\")\n\n# -- CRS (UTM 33N) -------------------------------------------------------------\nepsg <- \"EPSG:32633\"; sf_crs_utm33 <- sf::st_crs(epsg)\n\n# -- DEM laden, auflösen/projizieren, benennen --------------------------------\nDTM <- terra::rast(fn_DTM) |> terra::project(epsg) #|> terra::disagg(fact = c(20, 20)) |> terra::project(epsg)\nnames(DTM) <- \"altitude\"\nuse_topo=TRUE\n\n# WICHTIG: Passe den Pfad an dein Repo an; karim.R liefert u.a.:\n# extract_ecowitt_core_vars(), merge_ecowitt_logger_vars(),\n# clean_names(), clean_ids(), to_verbose(), fix_names(),\n# interpolate_kriging(), timeseries_panel(), pretty_time()\nsource(file.path(here::here(), \"karim.R\"))\n# OPTIONAL: Auflösungsvarianten (für Skalenvergleich)\n#DTM_1m <- DTM # (angenommen ~20 m nach disagg/proj; sonst terra::aggregate)\n# DTM_1m  <- terra::resample(DTM, terra::rast(res=1, ext=ext(DTM), crs=crs(DTM))) # nur wenn sinnvoll!\n# DTM_20cm <- ...  # Achtung: Speicher/Performance\n\n# -- Topografische Ableitungen -------------------------------------------------\nslope_r  <- terra::terrain(DTM, v = \"slope\", unit = \"degrees\")\naspect_r <- terra::terrain(DTM, v = \"aspect\", unit = \"degrees\")\nnames(slope_r)  <- \"slope_deg\"\nnames(aspect_r) <- \"aspect_deg\"\n\n# Eastness / Northness (zirkulare Codierung)\naspect_rad <- aspect_r * pi/180\neast_r  <- sin(aspect_rad); names(east_r)  <- \"aspect_sin\"\nnorth_r <- cos(aspect_rad); names(north_r) <- \"aspect_cos\"\n\n# -- Stationen & Fläche --------------------------------------------------------\nstations_pos <- sf::st_read(fn_stations) |> sf::st_transform(sf_crs_utm33)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `stations_prelim_modifiziert' from data source \n  `/home/creu/edu/gisma-courses/EON2025/block4_5/data_2024/stations_prelim_modifiziert.gpkg' \n  using driver `GPKG'\nSimple feature collection with 14 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 183043.8 ymin: 5748361 xmax: 183166.1 ymax: 5748507\nProjected CRS: WGS 84 / UTM zone 33N\n```\n\n\n:::\n\n```{.r .cell-code}\nplot_area    <- sf::st_read(fn_area)     |> sf::st_transform(sf_crs_utm33)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `plot' from data source \n  `/home/creu/edu/gisma-courses/EON2025/block4_5/data_2024/plot.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1 feature and 1 field\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 10.40154 ymin: 51.79506 xmax: 10.40658 ymax: 51.79803\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\n# -- Ecowitt-Daten: einlesen, bereinigen --------------------------------------\ntemp_FC29 <- extract_ecowitt_core_vars(fn_temp_FC29)\ntemp_DB2F <- extract_ecowitt_core_vars(fn_temp_DB2F)\nt_rh_all  <- merge_ecowitt_logger_vars(temp_FC29, temp_DB2F)\n\n# Logger-bewusste Namen\nt_rh_all$temperature <- t_rh_all$temperature %>% \n  dplyr::rename_with(~ to_verbose(.x, \"Temperature\"), -Time)\n\n# -- 3-h-Aggregation -----------------------------------------------------------\ntemp_agg <- t_rh_all$temperature %>%\n  dplyr::mutate(time = lubridate::floor_date(Time, \"3 hours\")) %>%\n  dplyr::group_by(time) %>%\n  dplyr::summarise(dplyr::across(where(is.numeric), ~ mean(.x, na.rm = TRUE)), .groups = \"drop\")\n\nnames(temp_agg) <- clean_ids(names(temp_agg))\n\n# Wide: station × time\ntemp_matrix <- temp_agg %>%\n  tidyr::pivot_longer(cols = -time, names_to = \"stationid\", values_to = \"value\") %>%\n  tidyr::pivot_wider(names_from = time, values_from = value)\n\n# -- Stationen mit Höhe & topografischen Ableitungen verknüpfen ---------------\nstations_pos <- stations_pos %>%\n  dplyr::mutate(\n    stationid = to_verbose(stationid),\n    altitude  = exactextractr::exact_extract(DTM, sf::st_buffer(stations_pos, 1), \"mean\"),\n    slope_deg = exactextractr::exact_extract(slope_r,  sf::st_buffer(stations_pos, 1), \"mean\"),\n    aspect_deg= exactextractr::exact_extract(aspect_r, sf::st_buffer(stations_pos, 1), \"mean\")\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |====================                                                  |  29%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |============================================================          |  86%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |====================                                                  |  29%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |============================================================          |  86%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |====================                                                  |  29%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |============================================================          |  86%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\n# Eastness/Northness auf Punktbasis\nstations_pos$aspect_sin <- sin(stations_pos$aspect_deg * pi/180)\nstations_pos$aspect_cos <- cos(stations_pos$aspect_deg * pi/180)\n\n# -- Join Temperaturwerte ------------------------------------------------------\nm <- dplyr::left_join(stations_pos, temp_matrix, by = \"stationid\")\nm$stationid <- gsub(\"\\\\(℃\\\\)|\\\\(％\\\\)|\\\\(\\\\%\\\\)\", \"\", m$stationid)\nnames(m)    <- fix_names(names(m))\n\n# -- Persistenz ----------------------------------------------------------------\nsaveRDS(m, cleandata_rds)\n\n# -- Grid-DF aus Raster-Stack (DEM + Ableitungen) ------------------------------\ntopo_stack <- c(DTM, slope_r, aspect_r, east_r, north_r) # 5 Layer\ngrid_df <- terra::as.data.frame(topo_stack, xy = TRUE, cells = TRUE, na.rm = FALSE)\nnames(grid_df) <- c(\"cell\",\"x\",\"y\",\"altitude\",\"slope_deg\",\"aspect_deg\",\"aspect_sin\",\"aspect_cos\")\n```\n:::\n\n\n\n> **Check-in**\n> *Sind Zeitaggregation, Koordinaten & Einheiten konsistent (°C, Grad vs. Radiant)? Ist die Skala der Topo-Kovariaten plausibel für den Prozess?*\n\n---\n\n# C. Methodenwahl & Implementierung\n\nWir vergleichen **KED (Regression-/Universal Kriging)**, **Voronoi**, **IDW**, **OK**, **TPS**, **GAM**, **RF**.\nAlle Methoden arbeiten auf *demselben* Zeitschritt und Dataset.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# -- Helfer: Punkte je Zeitstempel --------------------------------------------\n.get_pts_df <- function(v_name, m_sf) {\n  idx <- !is.na(m_sf[[v_name]])\n  if (!any(idx)) return(data.frame())\n  xy  <- sf::st_coordinates(m_sf[idx, ])\n  data.frame(\n    x = xy[,1], y = xy[,2],\n    altitude   = m_sf$altitude[idx],\n    slope_deg  = m_sf$slope_deg[idx],\n    aspect_deg = m_sf$aspect_deg[idx],\n    aspect_sin = m_sf$aspect_sin[idx],\n    aspect_cos = m_sf$aspect_cos[idx],\n    value      = m_sf[[v_name]][idx]\n  )\n}\n\n# -- Helper: Prediction-Vektor -> Raster --------------------------------------\n.pred_to_rast <- function(pred_vec, template_rast) {\n  r <- template_rast[[1]]\n  if (length(pred_vec) != terra::ncell(r)) stop(\"Prediction length vs raster cell count mismatch\")\n  terra::values(r) <- as.numeric(pred_vec); names(r) <- \"pred\"; r\n}\n\n# -- 1) Voronoi / Thiessen -----------------------------------------------------\npred_voronoi <- function(pts_df, DTM) {\n  if (!nrow(pts_df)) return(NA)\n  if (any(duplicated(pts_df[c(\"x\",\"y\")]))) {\n    pts_df$x <- pts_df$x + runif(nrow(pts_df), -0.001, 0.001)\n    pts_df$y <- pts_df$y + runif(nrow(pts_df), -0.001, 0.001)\n  }\n  ex <- terra::ext(DTM); rw <- c(ex$xmin, ex$xmax, ex$ymin, ex$ymax)\n  vd <- deldir::deldir(pts_df$x, pts_df$y, rw = rw)\n  tiles <- deldir::tile.list(vd)\n  close_ring <- function(coords) if (!all(coords[1,]==coords[nrow(coords),])) rbind(coords, coords[1,]) else coords\n  polys <- lapply(tiles, function(ti) sf::st_polygon(list(close_ring(cbind(ti$x, ti$y)))))\n  g <- sf::st_sf(value = pts_df$value, geometry = sf::st_sfc(polys, crs = sf::st_crs(m)))\n  g <- sf::st_make_valid(g)\n  dtm_poly <- sf::st_as_sfc(sf::st_bbox(terra::rast(DTM)), crs = sf::st_crs(m))\n  g_clip   <- suppressWarnings(sf::st_intersection(g, dtm_poly)) |> sf::st_collection_extract(\"POLYGON\")\n  r <- terra::rasterize(terra::vect(g_clip), DTM, field = \"value\"); names(r) <- \"voronoi\"; r\n}\n\n# -- 2) IDW --------------------------------------------------------------------\npred_idw <- function(pts_df, DTM, idp = 2) {\n  if (!nrow(pts_df)) return(NA)\n  sp::coordinates(pts_df) <- ~ x + y\n  sp::proj4string(pts_df) <- sf::st_crs(m)$wkt\n  p <- as.data.frame(grid_df[, c(\"x\",\"y\")]); sp::coordinates(p) <- ~ x + y; sp::gridded(p) <- TRUE\n  sp::proj4string(p) <- sf::st_crs(m)$wkt\n  idw_pred <- gstat::idw(value ~ 1, locations = pts_df, newdata = p, idp = idp)\n  r <- terra::rast(DTM); terra::values(r) <- as.numeric(idw_pred$var1.pred); names(r) <- \"idw\"; r\n}\n\n# -- 3) Ordinary Kriging -------------------------------------------------------\npred_ok <- function(pts_df, DTM) {\n  if (!nrow(pts_df)) return(NA)\n  sp::coordinates(pts_df) <- ~ x + y; sp::proj4string(pts_df) <- sf::st_crs(m)$wkt\n  vgm_mod <- automap::autofitVariogram(value ~ 1, pts_df)$var_model\n  p <- as.data.frame(grid_df[, c(\"x\",\"y\")]); sp::coordinates(p) <- ~ x + y; sp::gridded(p) <- TRUE\n  sp::proj4string(p) <- sf::st_crs(m)$wkt\n  kr <- gstat::krige(value ~ 1, pts_df, p, model = vgm_mod)\n  r <- terra::rast(DTM); terra::values(r) <- as.numeric(kr$var1.pred); names(r) <- \"ok\"; r\n}\n\n# -- 4) Thin-Plate Spline ------------------------------------------------------\npred_tps <- function(pts_df, DTM) {\n  if (!nrow(pts_df)) return(NA)\n  fit  <- fields::Tps(x = as.matrix(pts_df[, c(\"x\",\"y\")]), Y = pts_df$value)\n  pred <- fields::predict.Krig(fit, x = as.matrix(grid_df[, c(\"x\",\"y\")]))\n  r <- .pred_to_rast(pred, DTM); names(r) <- \"tps\"; r\n}\n\n# -- 5) GAM (mit Topo-Kovariaten) ---------------------------------------------\npred_gam <- function(pts_df, DTM) {\n  if (!nrow(pts_df)) return(NA)\n  df <- pts_df[complete.cases(pts_df[, c(\"x\",\"y\",\"altitude\",\"slope_deg\",\"aspect_sin\",\"aspect_cos\",\"value\")]), ]\n  n  <- nrow(df)\n  if (n < 5) return(.pred_to_rast(rep(mean(df$value, na.rm=TRUE), terra::ncell(DTM)), DTM))\n\n  # zentrieren/skalieren\n  cx <- mean(df$x);  sx <- sd(df$x);  if (!is.finite(sx) || sx == 0) sx <- 1\n  cy <- mean(df$y);  sy <- sd(df$y);  if (!is.finite(sy) || sy == 0) sy <- 1\n  ca <- mean(df$altitude); sa <- sd(df$altitude); if (!is.finite(sa) || sa == 0) sa <- 1\n  df$xs <- (df$x - cx)/sx\n  df$ys <- (df$y - cy)/sy\n  df$as <- (df$altitude - ca)/sa\n\n  # weiche k-Wahl\n  k_xy  <- min(max(5, floor(n/4)), n - 1, 40)\n  k_alt <- min(max(3, floor(n/6)), n - 1, 10)\n  k_s   <- min(max(3, floor(n/6)), n - 1, 10)\n\n  fit <- try(mgcv::gam(\n    value ~ s(xs, ys, k = k_xy, bs = \"tp\") +\n            s(as, k = k_alt, bs = \"tp\") +\n            s(slope_deg, k = k_s, bs = \"tp\") +\n            s(aspect_sin, aspect_cos, k = k_s, bs = \"tp\"),\n    data = df, method = \"REML\", select = TRUE\n  ), silent = TRUE)\n\n  if (inherits(fit, \"try-error\")) {\n    fit <- lm(value ~ as + slope_deg + aspect_sin + aspect_cos, data = df)\n  }\n\n  nd <- grid_df\n  nd$xs <- (nd$x - cx)/sx\n  nd$ys <- (nd$y - cy)/sy\n  nd$as <- (nd$altitude - ca)/sa\n  pred <- as.numeric(predict(fit, newdata = nd, type = \"response\"))\n  r <- .pred_to_rast(pred, DTM); names(r) <- \"gam\"; r\n}\n\n# -- 6) Random Forest ----------------------------------------------------------\npred_rf <- function(pts_df, DTM) {\n  if (!nrow(pts_df)) return(NA)\n  train <- pts_df[complete.cases(pts_df[, c(\"x\",\"y\",\"altitude\",\"slope_deg\",\"aspect_sin\",\"aspect_cos\",\"value\")]), ]\n  if (nrow(train) < 5) return(.pred_to_rast(rep(mean(train$value, na.rm=TRUE), terra::ncell(DTM)), DTM))\n  fit  <- randomForest::randomForest(value ~ x + y + altitude + slope_deg + aspect_sin + aspect_cos,\n                                     data = train, ntree = 500)\n  pred <- predict(fit, newdata = grid_df)\n  r <- .pred_to_rast(as.numeric(pred), DTM); names(r) <- \"rf\"; r\n}\n\n# -- 7) KED / Regression-Kriging (value ~ altitude [+ optional slope/aspect]) --\n# Kompakter, unabhängiger RK-Wrapper (ohne Repo-Funktion), für LOO-CV geeignet\npred_ked <- function(pts_df, DTM, use_topo = FALSE) {\n  if (!nrow(pts_df)) return(NA)\n  df <- pts_df[complete.cases(pts_df[, c(\"x\",\"y\",\"altitude\",\"value\",\n                                         \"slope_deg\",\"aspect_sin\",\"aspect_cos\")]), ]\n  if (nrow(df) < 5) return(.pred_to_rast(rep(mean(df$value, na.rm=TRUE), terra::ncell(DTM)), DTM))\n\n  if (use_topo) {\n    drift_formula <- value ~ altitude + slope_deg + aspect_sin + aspect_cos\n  } else {\n    drift_formula <- value ~ altitude\n  }\n\n  # Trendmodell (OLS)\n  lm_fit <- lm(drift_formula, data = df)\n  df$resid <- residuals(lm_fit)\n\n  # Variogramm der Residuen + Kriging\n  sp::coordinates(df) <- ~ x + y; sp::proj4string(df) <- sf::st_crs(m)$wkt\n  vgm_mod <- automap::autofitVariogram(resid ~ 1, df)$var_model\n\n  p <- as.data.frame(grid_df[, c(\"x\",\"y\")])\n  sp::coordinates(p) <- ~ x + y; sp::gridded(p) <- TRUE\n  sp::proj4string(p) <- sf::st_crs(m)$wkt\n\n  kr_res <- gstat::krige(resid ~ 1, df, p, model = vgm_mod)\n  res_pred <- as.numeric(kr_res$var1.pred)\n\n  # Drift auf Gitter vorhersagen\n  drift_pred <- predict(lm_fit, newdata = grid_df)\n  pred <- drift_pred + res_pred\n\n  r <- terra::rast(DTM); terra::values(r) <- pred; names(r) <- \"ked\"\n  r\n}\n```\n:::\n\n\n\n> **Denkbox**\n> Welche Methoden sind besonders *clustering-sensitiv* (nahe Stationen dominieren)?\n> In welchen Situationen ist ein **Trendmodell** (KED/RK) physikalisch geboten?\n\n---\n\n# D. Anwendung, Vergleich & Validierung\n\nWir führen alle Methoden auf einem Beispiel-Zeitschritt aus, vergleichen Karten, evaluieren mit **Leave-One-Out** und visualisieren Fehlermaße.\n\n## D.1 Methodenvergleich (ein Zeitstempel)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# -- Zeitspalten finden --------------------------------------------------------\nvars <- as.list(grep(\"^A\\\\d{4}\", names(m), value = TRUE))  # z.B. \"A2023...\"\n\n# Einen Zeitstempel auswählen (z. B. 9.)\nv <- vars[[9]]\nstopifnot(length(v) == 1)\nts_label <- pretty_time(v)\n# NaN in allen Zeitspalten in NA umwandeln\nm <- m %>%\n  dplyr::mutate(dplyr::across(matches(\"^A\\\\d+\"), ~ ifelse(is.nan(.x), NA_real_, .x)))\n# falls aspect_cos fehlt: aus aspect_deg berechnen\nif (!\"aspect_cos\" %in% names(m)) {\n  m$aspect_cos <- cos(m$aspect_deg * pi/180)\n  # Flats: falls slope sehr klein/NA, ex/north auf 0 setzen\n  m$aspect_sin[is.na(m$slope_deg) | m$slope_deg < 0.01] <- 0\n  m$aspect_cos[is.na(m$slope_deg) | m$slope_deg < 0.01] <- 0\n}\n# Punktdaten (x,y + Kovariaten + value)\npts <- .get_pts_df(v, m)\n\n# Vorhersagen\nr_ked   <- pred_ked(pts, DTM, use_topo = TRUE)  # RK mit altitude + slope/aspect\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[using ordinary kriging]\n```\n\n\n:::\n\n```{.r .cell-code}\nr_voro  <- pred_voronoi(pts, DTM)\nr_idw   <- pred_idw(pts, DTM, idp = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[inverse distance weighted interpolation]\n```\n\n\n:::\n\n```{.r .cell-code}\nr_ok    <- pred_ok(pts, DTM)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[using ordinary kriging]\n```\n\n\n:::\n\n```{.r .cell-code}\nr_tps   <- pred_tps(pts, DTM)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nWarning: \nGrid searches over lambda (nugget and sill variances) with  minima at the endpoints: \n  (GCV) Generalized Cross-Validation \n   minimum at  right endpoint  lambda  =  58.52957 (eff. df= 3.001006 )\n```\n\n\n:::\n\n```{.r .cell-code}\nr_gam   <- pred_gam(pts, DTM)\nr_rf    <- pred_rf(pts, DTM)\n\n# Stack & Export\nout_dir  <- file.path(here::here(), \"interpolated_raw\"); if (!dir.exists(out_dir)) dir.create(out_dir, recursive = TRUE)\nout_dir2 <- file.path(out_dir, \"methods_compare_raw\"); if (!dir.exists(out_dir2)) dir.create(out_dir2, recursive = TRUE)\n\nlst <- list(KED=r_ked, Voronoi=r_voro, IDW=r_idw, OK=r_ok, TPS=r_tps, GAM=r_gam, RF=r_rf)\nlst <- lst[!sapply(lst, function(x) {\n  is.null(x) || all(is.na(as.vector(x)))\n})]\nlst <- lapply(lst, function(x) if (inherits(x,\"stars\")) terra::rast(x) else x)\n\nstack_example <- terra::rast(lst)\nnames(stack_example) <- names(lst)  # Bändern sinnvolle Namen geben\nterra::writeRaster(stack_example, file.path(out_dir2, paste0(\"compare_stack_\", ts_label, \".tif\")), overwrite = TRUE)\n```\n:::\n\n\n\n## D.2 Visualisierung (gezoomt auf Stationsbereich)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbb  <- sf::st_bbox(sf::st_union(stations_pos))\npad <- 0.05\nxlim_zoom <- c(bb[\"xmin\"] - pad*(bb[\"xmax\"]-bb[\"xmin\"]), bb[\"xmax\"] + pad*(bb[\"xmax\"]-bb[\"xmin\"]))\nylim_zoom <- c(bb[\"ymin\"] - pad*(bb[\"ymax\"]-bb[\"ymin\"]), bb[\"ymax\"] + pad*(bb[\"ymax\"]-bb[\"ymin\"]))\next_zoom  <- terra::ext(xlim_zoom[1], xlim_zoom[2], ylim_zoom[1], ylim_zoom[2])\n\n.rast_to_df <- function(r, name) {\n  r <- terra::crop(r, ext_zoom, snap = \"out\")\n  if (all(is.na(terra::values(r)))) return(NULL)\n  s <- stars::st_as_stars(r); names(s) <- \"value\"\n  df <- as.data.frame(s, xy = TRUE, na.rm = TRUE); df$method <- name; df\n}\n\ndf_list <- lapply(names(lst), function(nm) .rast_to_df(lst[[nm]], nm))\ndf_list <- df_list[!sapply(df_list, is.null)]\ndf_all  <- dplyr::bind_rows(df_list)\n\np_methods <- ggplot2::ggplot(df_all, ggplot2::aes(x=x, y=y, fill=value)) +\n  ggplot2::geom_raster() +\n  ggplot2::facet_wrap(~ method, ncol = 3) +\n  ggplot2::scale_fill_viridis_c(name = \"Temperature\") +\n  ggplot2::coord_cartesian(xlim = xlim_zoom, ylim = ylim_zoom, expand = FALSE) +\n  ggplot2::geom_sf(data = plot_area, inherit.aes = FALSE, color = \"black\", linewidth = 0.3, fill = NA) +\n  ggplot2::geom_sf(data = stations_pos, inherit.aes = FALSE, shape = 21, fill = NA, color = \"black\", size = 1.5) +\n  ggplot2::labs(title = paste0(\"Methodenvergleich — \", ts_label)) +\n  ggplot2::scale_x_continuous(n.breaks = 3) +\n  ggplot2::scale_y_continuous(n.breaks = 3) +\n  ggplot2::theme_minimal(base_size = 12) +\n  ggplot2::scale_x_continuous(guide = ggplot2::guide_axis(angle = 45))+\n \n  ggplot2::theme(\n    legend.position = \"right\",\n    plot.title = ggplot2::element_text(face = \"bold\")\n  )\n\nggplot2::ggsave(file.path(out_dir2, paste0(\"methods_compare_ggplot_\", ts_label, \".png\")),\n                p_methods, width = 10, height = 8, dpi = 200)\np_methods\n```\n\n::: {.cell-output-display}\n![](mc2_v2_enriched_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n> **Reflexionsfragen**\n>\n> * Welche Methoden zeigen **Kanten** (Voronoi/IDW)? Sind diese realistisch?\n> * Wo ist der **Höhentrend** sichtbar? Wie wirkt **Exposition**?\n> * Welche Methode glättet über **Senken** hinweg (Kaltluft)?\n\n \n# Kontext & Beobachtungen (Ihre Domäne)\n\n* **Domäne:** \\~**120 × 120 m** Kahlschlag/Dürrständer-Patch.\n* **Stationsgeometrie:** stark **geclustert**, effektiv \\~**12 DEM-Zellen**.\n* **Topographie:** **9.3 m** Höhenhub ⇒ **≈ 0.06 K** erwarteter Temperaturunterschied (mit \\~6.5 K/km Standard-Umweltgradient). Auf dieser Skala ist der Höheneffekt **unter dem Mess-/Modellrauschen**. ([fisicaatmo.at.fcen.uba.ar][1], [Wikipedia][2])\n\n# Dominierende Prozesse & passende Skalen\n\n1. **Strahlungsgeometrie / Sky-View-Factor (SVF)**\n   Auf offenen Flächen steuert die „Himmelssicht“ (Abschirmung vs. freie Ausstrahlung) die nächtliche Abkühlung und die kurzwellige Einstrahlung am Tag. SVF wirkt auf **10–100 m** und erklärt systematische Temperaturunterschiede nahe Kanten/Objekten — deutlich relevanter als 9 m Höhenhub. ([bayanbox.ir][3], [Royal Meteorological Society][4], [ScienceDirect][5])\n\n2. **Rauigkeit, Fetch & interne Grenzschicht (IBL)**\n   Der Wechsel **Wald → Offenfläche** erzeugt eine **interne Grenzschicht**, die mit dem **Fetch** wächst; Wind- und Turbulenzanpassung (z₀, d) steuern sensible/latente Wärmeflüsse. Charakteristische Längenskalen liegen bei **Dutzenden bis Hunderten Metern** (stabilitäts- und windabhängig). ([ADS][6], [American Meteorological Society Journals][7], [SpringerLink][8])\n\n3. **Kanten-/Advektionseffekte**\n   Entlang **Bestandskanten** entstehen Mikro-Advektion und Temperaturgradienten vom Wald in die Lichtung. Feldstudien zeigen **deutliche Mikroklima-Gradienten** von der Kahlschlagkante weit in den Bestand hinein (bis **100–250 m**, witterungsabhängig). ([JSTOR][9], [Andrews Forest Research Program][10])\n\n4. **Stabilität / MOST-Skalierung**\n   Bei **konvektiven Tagen** dominieren Einstrahlung, Rauigkeit und Fetch; in **stabilen Nächten** verstärken sich SVF- und Kanten-Einflüsse, während die klassische MOST-Annahme „flach & homogen“ auf Ihrer Patch-Skala nur begrenzt gilt. ([ftp.soest.hawaii.edu][11], [SpringerLink][12])\n\n# Konsequenzen für Methoden (Ergebnis-Bezug)\n\n* **KED (DEM-Drift):** Auf Ihrer Skala **kein nutzbares Topo-Signal** → der Drift ist **reiner Lärm**; Residual-Variogramm wird instabil ⇒ **RMSE/Bias steigen** (genau das sieht man). **DEM als Drift hier weglassen**. ([fisicaatmo.at.fcen.uba.ar][1])\n* **OK (reines Variogramm):** Bei **Cluster & Replikaten** in wenigen Zellen wird die Variogramm-Schätzung fragil (großer Mikronugget). Falls OK: **zellweise mitteln** (1 Wert/Zelle) und **Nugget fixieren**. (Grundlegend variogramm-/IBL-sensitiv, siehe Roughness/IBL-Literatur.) ([ADS][6])\n* **Voronoi/IDW/TPS/RF:** Bei **glattem Feld** auf 120 m und enger Nachbarschaft performen **Nähe-Methoden** robust. Voronoi profitiert in **LOO** überproportional (nächster Nachbar sehr nah), zeigt aber **Bias** bei großskaligen Gradienten. **TPS/IDW** als verlässliche Baseline.\n* **GAM/KED mit „richtigen“ Drifts:** Statt Höhe **SVF**, **Distanz/Orientierung zur Kante**, **Fetch/Exposition** (glätten/aggregieren auf **\\~50–150 m**, also Stations-/Prozessskala) — dann Drift sinnvoll. ([bayanbox.ir][3], [ADS][6])\n\n# Datenvalidierung & CV\n\n* **Punkt-LOO überschätzt** Nähe-Methoden bei Clusterung. Nutzen Sie **räumlich blockierte CV** (z. B. **Leave-cell-out**, NNDM oder Blocks \\~50–150 m). Das ist Standard, um räumliche Autokorrelation zu entschärfen. ([WSL][13], [British Ecological Society Journals][14], [GitHub][15])\n\n# Praktische To-dos (auf Ihrer 120 m-Domäne)\n\n1. **Drifts in Prozess-Skala**:\n\n   * **SVF\\_100 m** (aus CHM/DSM), **Distanz & Orientierung zur Kante**, **Fetch/Exposition** (windrichtungsabhängig), ggf. **Feuchte/NDVI** falls vorhanden.\n   * Kovariaten **glätten/aggregieren auf 50–150 m** (≈ Stationsabstand/IBL-Anpassung), keine Mikro-Texturen einspeisen. ([bayanbox.ir][3], [ADS][6])\n2. **Modelle**:\n\n   * **Baseline-Karte:** **TPS** oder **IDW (p≈1.5–2)**.\n   * **Erweiterung:** **GAM:** `y ~ s(x,y,k) + s(SVF_100m,k=3) + s(dist_edge,k=3)` (REML). **Kein** Höhen-Drift.\n3. **OK robust machen (optional):** Zell-Mittelung, **Nugget fix**, Cutoff \\~ halbe Gebietdiagonale.\n4. **CV:** **Block-CV** (z. B. blockCV/NNDM) und **Leave-cell-out** für ehrliche Fehler. ([British Ecological Society Journals][14])\n\n# Kurzfazit (Skalen ↔ Prozesse)\n\n* **Topographie** (9.3 m) → **≈ 0.06 K**: **irrelevant** auf 120 m. **KED schadet.** ([fisicaatmo.at.fcen.uba.ar][1])\n* **Struktur- & Energieprozesse** (SVF, Kante, Fetch, Rauigkeit) dominieren auf **10–200 m**. **Drifts müssen diese Skala treffen**, nicht die 25 m-DEM-Textur. ([bayanbox.ir][3], [ADS][6], [JSTOR][9])\n* **Validierung**: **Räumlich blocken**, sonst sind Nähe-Methoden (Voronoi/IDW) **zu optimistisch**. ([WSL][13])\n\n---\n\n## Quellen (Auswahl)\n\n* **Clearcut-Mikroklima / Kanten-Gradienten:** Chen, Franklin & Spies 1993, 1995. ([Andrews Forest Research Program][16], [JSTOR][9])\n* **Rauigkeit & Verschiebungsebene (z₀, d):** Raupach 1994; Verhoef 1997. ([SpringerLink][8], [HESS][17])\n* **SVF & Strahlungsgeometrie:** Oke 1987 (Boundary Layer Climates); Svensson 2004; Middel et al. 2018 (Überblick). ([bayanbox.ir][3], [Royal Meteorological Society][4], [ScienceDirect][5])\n* **IBL / Fetch über Rauigkeitswechsel:** Garratt 1990 (Review); LeMone et al. 2019 (Monograph). ([ADS][6], [American Meteorological Society Journals][7])\n* **MOST / Stabilität (Grundlagen):** Stull 1988 (Textbook); Sun 2020 (Review). ([ftp.soest.hawaii.edu][11], [SpringerLink][12])\n* **Räumliche Cross-Validation:** Roberts et al. 2017; Valavi et al. 2019 & blockCV. ([WSL][13], [British Ecological Society Journals][14], [mirror.uned.ac.cr][18])\n* **Standard-Umwelt-Gradient (\\~6.5 K/km):** ISA/US-Standard-Atmosphäre. ([fisicaatmo.at.fcen.uba.ar][1], [ngdc.noaa.gov][19])\n\nWenn du willst, setze ich dir das direkt in deinen QMD-Abschnitt „Prozesse & Skalen“ ein—ohne Reformatierung des restlichen Dokuments.\n\n[1]: https://fisicaatmo.at.fcen.uba.ar/practicas/ISAweb.pdf?utm_source=chatgpt.com \"The International Standard Atmosphere (ISA)\"\n[2]: https://en.wikipedia.org/wiki/Lapse_rate?utm_source=chatgpt.com \"Lapse rate\"\n[3]: https://bayanbox.ir/view/6693893538424427706/T.-R.-Oke-Boundary-Layer-Climates-Second-Editio-BookFi.org.pdf?utm_source=chatgpt.com \"Boundary Layer Climates, Second Edition\"\n[4]: https://rmets.onlinelibrary.wiley.com/doi/pdf/10.1017/S1350482704001288?utm_source=chatgpt.com \"Sky view factor analysis – implications for urban air ...\"\n[5]: https://www.sciencedirect.com/science/article/pii/S2212095518301883?utm_source=chatgpt.com \"Sky View Factor footprints for urban climate modeling\"\n[6]: https://ui.adsabs.harvard.edu/abs/1990BoLMe..50..171G/abstract?utm_source=chatgpt.com \"The internal boundary layer — A review - ADS\"\n[7]: https://journals.ametsoc.org/downloadpdf/view/journals/amsm/59/1/amsmonographs-d-18-0013.1.pdf?utm_source=chatgpt.com \"Chapter 9 100 Years of Progress in Boundary Layer ...\"\n[8]: https://link.springer.com/article/10.1007/BF00709229?utm_source=chatgpt.com \"Simplified expressions for vegetation roughness length ...\"\n[9]: https://www.jstor.org/stable/1942053?utm_source=chatgpt.com \"Growing-Season Microclimatic Gradients from Clearcut ...\"\n[10]: https://andrewsforest.oregonstate.edu/pubs/pdf/pub2095.pdf?utm_source=chatgpt.com \"growing-season microclimatic gradients from clearcut edges ...\"\n[11]: https://ftp.soest.hawaii.edu/kelvin/OCN665/OCN665_full/An%2BIntroduction%2Bto%2BBoundary%2BLayer%2BMeteor.pdf?utm_source=chatgpt.com \"An+Introduction+to+Boundary+Layer ...\"\n[12]: https://link.springer.com/article/10.1007/s10546-020-00546-5?utm_source=chatgpt.com \"Understanding Physical Processes Represented by the ...\"\n[13]: https://www.wsl.ch/lud/biodiversity_events/papers/Roberts_et_al-2017-Ecography.pdf?utm_source=chatgpt.com \"Cross-validation strategies for data with temporal, spatial, ...\"\n[14]: https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.13107?utm_source=chatgpt.com \"blockCV: An r package for generating spatially or ...\"\n[15]: https://github.com/rvalavi/blockCV?utm_source=chatgpt.com \"rvalavi/blockCV\"\n[16]: https://andrewsforest.oregonstate.edu/publications/1420?utm_source=chatgpt.com \"Contrasting microclimates among clearcut, edge, and ...\"\n[17]: https://hess.copernicus.org/articles/1/81/1997/hess-1-81-1997.pdf?utm_source=chatgpt.com \"A parameterization of momentum roughness length and ...\"\n[18]: https://mirror.uned.ac.cr/cran/web/packages/blockCV/blockCV.pdf?utm_source=chatgpt.com \"blockCV: Spatial and Environmental Blocking for K-Fold ...\"\n[19]: https://www.ngdc.noaa.gov/stp/space-weather/online-publications/miscellaneous/us-standard-atmosphere-1976/us-standard-atmosphere_st76-1562_noaa.pdf?utm_source=chatgpt.com \"US Standard Atmosphere, 1976\"\n\n\n## D.3 Leave-One-Out Cross-Validation (LOO-CV)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Methoden-Kapsel als Liste kompatibler Funktionszeiger\nmethods <- list(\n  KED     = function(pts, DTM) pred_ked(pts, DTM, use_topo = TRUE),\n  Voronoi = pred_voronoi,\n  IDW     = pred_idw,\n  OK      = pred_ok,\n  TPS     = pred_tps,\n  GAM     = pred_gam,\n  RF      = pred_rf\n)\n\n# LOO-CV Helfer\nloo_cv <- function(method_fun, pts_df, DTM) {\n  if (!nrow(pts_df)) return(NULL)\n  res <- lapply(seq_len(nrow(pts_df)), function(i) {\n    train <- pts_df[-i, , drop = FALSE]\n    test  <- pts_df[i, ,  drop = FALSE]\n    r <- try(method_fun(train, DTM), silent = TRUE)\n    if (inherits(r, \"try-error\") || (inherits(r, \"SpatRaster\") && !terra::hasValues(r))) {\n  # next / return(NULL) – je nach deiner Schleifenlogik\n}\n    pv <- terra::extract(r, matrix(c(test$x, test$y), ncol = 2))[,1]\n    if (is.na(pv)) return(NULL)\n    data.frame(obs = test$value, pred = pv)\n  })\n  do.call(rbind, res)\n}\n\n# LOO-CV je Methode\ncv_results <- purrr::imap(methods, function(fun, name) {\n  df <- loo_cv(fun, pts, DTM)\n  if (!is.null(df) && nrow(df)) { df$method <- name; df } else NULL\n})\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[using ordinary kriging]\n[using ordinary kriging]\n[using ordinary kriging]\n[using ordinary kriging]\n[using ordinary kriging]\n[using ordinary kriging]\n[using ordinary kriging]\n[using ordinary kriging]\n[using ordinary kriging]\n[using ordinary kriging]\n[using ordinary kriging]\n[using ordinary kriging]\n[using ordinary kriging]\n[using ordinary kriging]\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[inverse distance weighted interpolation]\n[inverse distance weighted interpolation]\n[inverse distance weighted interpolation]\n[inverse distance weighted interpolation]\n[inverse distance weighted interpolation]\n[inverse distance weighted interpolation]\n[inverse distance weighted interpolation]\n[inverse distance weighted interpolation]\n[inverse distance weighted interpolation]\n[inverse distance weighted interpolation]\n[inverse distance weighted interpolation]\n[inverse distance weighted interpolation]\n[inverse distance weighted interpolation]\n[inverse distance weighted interpolation]\n[using ordinary kriging]\n[using ordinary kriging]\n[using ordinary kriging]\n[using ordinary kriging]\n[using ordinary kriging]\n[using ordinary kriging]\n[using ordinary kriging]\n[using ordinary kriging]\n[using ordinary kriging]\n[using ordinary kriging]\n[using ordinary kriging]\n[using ordinary kriging]\n[using ordinary kriging]\n[using ordinary kriging]\nWarning: \nGrid searches over lambda (nugget and sill variances) with  minima at the endpoints: \n  (GCV) Generalized Cross-Validation \n   minimum at  right endpoint  lambda  =  54.4034 (eff. df= 3.00097 )\nWarning: \nGrid searches over lambda (nugget and sill variances) with  minima at the endpoints: \n  (GCV) Generalized Cross-Validation \n   minimum at  right endpoint  lambda  =  55.74542 (eff. df= 3.000995 )\nWarning: \nGrid searches over lambda (nugget and sill variances) with  minima at the endpoints: \n  (GCV) Generalized Cross-Validation \n   minimum at  right endpoint  lambda  =  53.0937 (eff. df= 3.001007 )\nWarning: \nGrid searches over lambda (nugget and sill variances) with  minima at the endpoints: \n  (GCV) Generalized Cross-Validation \n   minimum at  right endpoint  lambda  =  54.84711 (eff. df= 3.001006 )\nWarning: \nGrid searches over lambda (nugget and sill variances) with  minima at the endpoints: \n  (GCV) Generalized Cross-Validation \n   minimum at  right endpoint  lambda  =  59.00693 (eff. df= 3.00099 )\nWarning: \nGrid searches over lambda (nugget and sill variances) with  minima at the endpoints: \n  (GCV) Generalized Cross-Validation \n   minimum at  right endpoint  lambda  =  54.84711 (eff. df= 3.001003 )\nWarning: \nGrid searches over lambda (nugget and sill variances) with  minima at the endpoints: \n  (GCV) Generalized Cross-Validation \n   minimum at  right endpoint  lambda  =  55.74542 (eff. df= 3.000994 )\nWarning: \nGrid searches over lambda (nugget and sill variances) with  minima at the endpoints: \n  (GCV) Generalized Cross-Validation \n   minimum at  right endpoint  lambda  =  52.66418 (eff. df= 3.001067 )\nWarning: \nGrid searches over lambda (nugget and sill variances) with  minima at the endpoints: \n  (GCV) Generalized Cross-Validation \n   minimum at  right endpoint  lambda  =  61.45277 (eff. df= 3.000998 )\nWarning: \nGrid searches over lambda (nugget and sill variances) with  minima at the endpoints: \n  (GCV) Generalized Cross-Validation \n   minimum at  right endpoint  lambda  =  57.5864 (eff. df= 3.000997 )\nWarning: \nGrid searches over lambda (nugget and sill variances) with  minima at the endpoints: \n  (GCV) Generalized Cross-Validation \n   minimum at  right endpoint  lambda  =  55.74542 (eff. df= 3.000997 )\nWarning: \nGrid searches over lambda (nugget and sill variances) with  minima at the endpoints: \n  (GCV) Generalized Cross-Validation \n   minimum at  right endpoint  lambda  =  53.0937 (eff. df= 3.001005 )\nWarning: \nGrid searches over lambda (nugget and sill variances) with  minima at the endpoints: \n  (GCV) Generalized Cross-Validation \n   minimum at  right endpoint  lambda  =  56.65843 (eff. df= 3.001004 )\nWarning: \nGrid searches over lambda (nugget and sill variances) with  minima at the endpoints: \n  (GCV) Generalized Cross-Validation \n   minimum at  right endpoint  lambda  =  50.98055 (eff. df= 3.00103 )\n```\n\n\n:::\n\n```{.r .cell-code}\ncv_df <- dplyr::bind_rows(cv_results)\n\n# Fehlermaße\ncv_summary <- cv_df %>%\n  dplyr::group_by(method) %>%\n  dplyr::summarise(\n    RMSE = sqrt(mean((obs - pred)^2, na.rm = TRUE)),\n    MAE  = mean(abs(obs - pred), na.rm = TRUE),\n    Bias = mean(pred - obs, na.rm = TRUE),\n    .groups = \"drop\"\n  )\ncv_summary\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"method\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"RMSE\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"MAE\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Bias\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"GAM\",\"2\":\"3.674149\",\"3\":\"3.1632560\",\"4\":\"2.75680413\"},{\"1\":\"IDW\",\"2\":\"1.154260\",\"3\":\"0.9634326\",\"4\":\"0.20554890\"},{\"1\":\"KED\",\"2\":\"2.062260\",\"3\":\"1.7080845\",\"4\":\"0.70059363\"},{\"1\":\"OK\",\"2\":\"1.556526\",\"3\":\"1.2855357\",\"4\":\"0.07246623\"},{\"1\":\"RF\",\"2\":\"1.364604\",\"3\":\"1.0927025\",\"4\":\"0.63927811\"},{\"1\":\"TPS\",\"2\":\"1.108931\",\"3\":\"0.8693028\",\"4\":\"0.03148694\"},{\"1\":\"Voronoi\",\"2\":\"1.114936\",\"3\":\"0.7469387\",\"4\":\"-0.08265299\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n### Visualisierung der Fehlermaße\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncv_long <- tidyr::pivot_longer(cv_summary, cols = c(RMSE, MAE, Bias),\n                               names_to = \"metric\", values_to = \"value\")\n\nggplot(cv_long, aes(x = reorder(method, value), y = value, fill = method)) +\n  geom_col() +\n  facet_wrap(~ metric, scales = \"free_y\") +\n  labs(title = paste(\"LOO-CV –\", ts_label), x = \"Methode\", y = \"Fehler\") +\n  theme_minimal(base_size = 12) +\n  theme(legend.position = \"none\", axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](mc2_v2_enriched_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n> **Interpretation**\nKurzlese der CV-Tabelle (Bias = mean(pred − obs)):\n\n* Voronoi: RMSE 0.97 (best), MAE 0.66 (best), Bias −0.36 → nächster-Nachbar trifft LOO an der Messstelle erstaunlich gut, aber systematische Unterschätzung.\n\n* TPS / IDW / RF: RMSE ~1.16–1.21, MAE ~0.82–0.87, Bias nahe 0 → robuste, glatte Interpolatoren ohne starke Systematik.\n\n* OK: RMSE 1.52, MAE 1.27, Bias +0.08 → solide, aber Variogramm bei wenig/ungünstig verteilten Stationen offenbar instabil.\n\n* GAM: RMSE 1.42, MAE 1.08, Bias +0.10 → etwas schlechter als IDW/TPS/RF; Smoothing-Parameter/Termstruktur passt wohl nicht perfekt.\n\n* KED: RMSE 1.87 (schlechtest), MAE 1.48, Bias +0.30 → Drift (DEM) schadet hier; Überhöhung der Vorhersage.\n\n## D.4 (Optional) Residuenkarten (Beispiel GAM)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred_gam_map <- r_gam\nresid_gam <- pred_gam_map; terra::values(resid_gam) <- NA\n\nfor (i in 1:nrow(pts)) {\n  xy <- matrix(c(pts$x[i], pts$y[i]), ncol = 2)\n  val <- terra::extract(pred_gam_map, xy)[,1] - pts$value[i]\n  cell <- terra::cellFromXY(resid_gam, xy)\n  if (!is.na(cell)) terra::values(resid_gam)[cell] <- val\n}\n\nplot(resid_gam, main = paste(\"Residuen GAM —\", ts_label))\n```\n\n::: {.cell-output-display}\n![](mc2_v2_enriched_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n> **Praxis-Tipp**\n>\n> * **Negative** Residuen am Talboden? → Kaltluft unterschätzt?\n> * **Positive** Residuen auf sonnenexponierten Hängen? → Exposition im Modell zu schwach?\n\n---\n\n# E. Skalen-Experimente (optional)\n\nVergleiche **DEM-Auflösungen** (z. B. 20 m vs. 1 m) und **Kovariatensätze**:\n\n\n> **Reflexion**\n>\n> * Bringt **höhere DEM-Auflösung** tatsächlich bessere Vorhersagen – oder nur feinere Artefakte?\n> * Verbessern **Slope/Aspect** das Modell *zeitlich stabil* (z. B. nachts vs. tags)?\n\n---\n\n# F. Hinweise & Ressourcen\n\n* Dieses QMD ist **kompakt & lauffähig**; die ausführlichen Hilfsfunktionen werden **gesourct**.\n* Die Vollskripte (z. B. `timeseries_panel()`) liegen im Kurs-Repo (`block4_5/`).\n* Achte auf **Speicher/Performance** bei hoher Auflösung; beschränke Extents und Zellenzahlen.\n* Einheitlichkeit prüfen: °C, Grad/Radiant, CRS.\n\n\n",
    "supporting": [
      "mc2_v2_enriched_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}